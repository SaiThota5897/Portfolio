{
  "last_updated": "2025-08-14T00:00:00Z",
  "content": {
    "name": "SAI THOTA",
    "role": "Senior AI/Machine Learning Engineer",
    "contact_line": "tsai58997@gmail.com | +1 (469) 573-2313 | LinkedIn | GitHub",
    "summary": "Over 8 years of experience delivering production-grade AI/ML solutions across Insurance, Cybersecurity, Healthcare, Environmental, and Manufacturing domains using Python, LangChain, Docker, and Databricks.\nSpearheaded design and deployment of multi-agent AI systems using OpenAI GPT-4 and private LLaMA 3 LLM stacks with LoRA/QLoRA optimization, enabling scalable and efficient generative AI workflows.\nLeveraged RAG pipelines, prompt engineering, agent evaluation & monitoring, and HITL mechanisms with ChromaDB to ensure reliability, accuracy, and compliance in AI decision-making.\nEngineered secure, multimodal AI pipelines for threat detection using PyTorch, OpenCV, and Weaviate, integrated with LangChain-powered RAG pipelines and self-hosted LLMs for real-time semantic analysis.\nProficient in fine-tuning and deploying transformer-based and deep learning models (ResNeXt-LSTM, WaveNet, GANs) and adversarial training for robust detection in multilingual and low-resolution environments.\nDelivered impactful AI solutions that accelerated claims processing, underwriting decisions, fraud detection, and patient satisfaction while reducing operational costs and manual review efforts.\nApplied ensemble learning, time-series forecasting, and graph-based models (LSTM, GNN, SARIMA) to optimize predictions and improve decision-making in high-volume, dynamic data environments.\nLed large-scale data engineering programs, including ingestion, streaming, batch processing, ETL/ELT, and warehousing using AWS (S3, Lambda, SageMaker, Glue), Databricks (PySpark, Delta Lake), Kafka, and Airflow.\nBuilt enterprise-grade MLOps workflows using Azure ML, AKS, MLflow, Docker, Kubernetes, FastAPI, and CI/CD automation, integrating telemetry, drift detection, and PHI/PII-safe governance for audit-ready deployments.\nDirected end-to-end data analytics and transformation workflows, turning raw datasets into actionable insights using SQL, Python, and visualization tools, and dashboards for reporting and operational efficiency.\nStrong foundation in statistical modeling, probability, and mathematical optimization to boost AI/ML model performance and reliability.",
    "skills": "",
    "experience": {
      "Allied World Assurance Company (AWAC)": "Role: Senior AI/ML Engineer\nDescription: Built secure, agentic AI systems to automate claims processing, fraud detection, and underwriting risk assessment. Prototyped agentic AI workflows using OpenAI APIs for rapid development. Migrated production deployments to a private LLaMA 3 stack on Azure, ensuring secure, scalable, and cost-efficient inference.\nKey Contributions:\n• Designed and deployed GPT-4–powered agents and private LLaMA 3 stacks with LoRA/QLoRA optimization for policy lookups, fraud detection, and claims triage, reducing manual processing time by 38%.\n• Developed an underwriting risk intelligence assistant using DeBERTa embeddings in LangChain RAG pipelines with ChromaDB, improving decision turnaround by 35% and quote accuracy.\n• Built multi-agent AI systems leveraging RAG pipelines, LangChain, LangFlow, prompt engineering, and agent evaluation & monitoring.\n• Introduced HITL mechanisms and fallback flows to mitigate risk from hallucinations or uncertain outputs.\n• Migrated prototypes to AKS using vLLM, reducing inference costs by 23% via quantization and LoRA/QLoRA.\n• Implemented LangFlow orchestration for multi-turn dialogs, document ingestion, and workflow automation.\n• Established agent evaluation & monitoring pipelines inspired by Arize/LLM-as-Judge techniques.\n• Engineered secure CI/CD pipelines with Azure ML, Azure DevOps, Docker, Kubernetes, and FastAPI.\n• Defined observability and telemetry requirements integrating Azure Monitor and OpenTelemetry.\nTechnical Stack: LangChain, LangGraph, LangFlow, AutoGen, Hugging Face Transformers (DeBERTa), LLaMA 3, vLLM, GPT-4, LoRA/QLoRA, ChromaDB, HITL, Azure ML, AKS, Azure DevOps, MLflow, Docker, Kubernetes, SQL Server, Cosmos DB, Prompt Engineering, Agent Evaluation & Monitoring, RAG, MLOps, Agile, Secure AI Deployment.",
      "McAfee": "Role: Data Scientist – LLMs & Generative AI\nDescription: Developed a secure AI-driven threat detection platform to identify deepfake media, voice cloning, and emerging cyber threats in real time.\nKey Contributions:\n• Integrated self-hosted Mistral LLM endpoints via LangChain-powered RAG pipelines with Weaviate VectorDB.\n• Reduced LLM hallucinations by 17% using LangSmith prompt optimization, achieving 87%+ detection accuracy and reducing false negatives by 18%.\n• Fine-tuned and deployed ResNeXt-LSTM, WaveNet, CNN-BiLSTM for forgery detection, voice cloning, and speech anomaly detection.\n• Enhanced robustness using GAN-generated adversarial samples.\n• Preprocessed multimodal data with PyTorch and OpenCV.\n• Designed secure ingestion pipelines with AWS VPC Peering, Kafka, Delta Lake, and Databricks.\n• Automated alerting via Databricks jobs, AWS Lambda, and secure orchestration.\n• Ensured GDPR and HIPAA compliance with IAM-based access control, encrypted data transit, and FastAPI secured with OAuth2/JWT.\nTechnical Stack: Python, PyTorch, LangSmith, LangChain, GAN, Databricks, PySpark, MLflow, Weaviate, Mistral, OpenCV, AWS Lambda, Kafka, Delta Lake, OAuth2/JWT, RAG, Multimodal Threat Detection, DFDC, Hallucination Detection.",
      "GE HealthCare": "Role: Senior Data Engineer\nDescription: Delivered scalable data pipelines and predictive models to optimize healthcare event logistics.\nKey Contributions:\n• Built a patient feedback analytics pipeline using spaCy, NLTK, VADER, Logistic Regression, K-Means, Apriori, and collaborative filtering.\n• Engineered dynamic route estimation with Google Maps APIs, saving $120K/month.\n• Trained LightGBM models to predict travel distances with 95%+ accuracy.\n• Applied SHAP/LIME for model interpretability.\n• Developed ETL pipelines in Python, SSRS, SQL.\n• Deployed analytics microservices using FastAPI and AWS.\nTechnical Stack: Python, SQL Server, SSRS, LightGBM, XGBoost, VADER, K-Means, Apriori, AWS Lambda, EC2, S3, FastAPI, Git, Jenkins, Agile, HIPAA Compliance, SHAP, LIME.",
      "N-iX": "Role: Python Developer\nDescription: Built an IoT-enabled agriculture analytics system.\nKey Contributions:\n• Conducted field surveys collecting 1,000+ farmer records in SQL Server.\n• Collaborated on IoT sensor manufacturing requirements.\n• Built Excel dashboards for reporting.\n• Preprocessed data in Python.\n• Developed a Flask-based web app integrated with LoRa modules.\n• Modeled relational data using SQLAlchemy.\nTechnical Stack: Questionnaire Design, IoT Collaboration, Python, SQL Server, SQLAlchemy, Excel, Flask, Jupyter, GitHub, LoRa IoT Devices."
    },
    "certifications": [
      "Databricks Generative AI Fundamentals",
      "Microsoft Azure AI Engineer Associate",
      "AWS Cloud Practitioner"
    ],
    "education": "Master of Science in Computer Science and Data Science Graduate at Utah State University, Logan, Utah"
  }
}
